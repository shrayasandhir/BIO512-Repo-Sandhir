{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"4.3.3"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"78f2fcd9-2cc5-4e31-8aa2-b47106d273ce","cell_type":"markdown","source":"# Homework 09\nThis homework is based on the classification and regression lectures.","metadata":{}},{"id":"064a600f-4693-4efc-8b3b-fa033a140406","cell_type":"markdown","source":"## Question 1\n#### In the table below, fill in the definition column with a short (no more than two sentence) definition for each vocab word. If it can be summarized by a formula, give the formula. \n\n| Vocab Word | Definition |\n|:--------|:--------|\n| **One-hot coding** |  The process of converting categorical data in a numerical format|\n| **Feature selection*** | The process of selecting certain features of the data to construct a model. |\n| **Classifier** | A classifier is an algorithm that assigns data points a category based on its features. |\n| **Precision** | True positive / (true positive + false positive) |\n| **Recall** | True positive / (true positive + false negative) |\n| **F1 Score** | (2 x precision x recall)/(precision + recall) |\n| **Parsimonious model** | The model that explains data with the fewest parameters while preserving accuracy. |\n| **Ridge regression** | A linear regression that adds an L2 penalty. This makes the regression less prone to overfitting. |\n| **LASSO regression** | A linear regression that adds an L1 penalty. This removes less important coefficients from the model. |\n| **Cross validation** | A technique that splits data into training and testing sets to see how well a model can generalize. |\n| **Tree based methods** | Algorithms that segments variables into branches that are tested for accuracy and efficiency. |\n\n*Just give the general idea.","metadata":{}},{"id":"77d3f305-b18b-4a5d-81b8-0db018c3c9d3","cell_type":"markdown","source":"## Question 2 \n#### a) What shape does a perfect classifier look like on an ROC curve? What about a bad classifier?\n#### b) Think about the formula for an F1 score. What does it mean when the F1 score is close to 1? Close to 0?","metadata":{}},{"id":"84ea0637-306c-46c9-9d87-05713f33a271","cell_type":"markdown","source":"a) A perfect shape for a classifier on a ROC curve will be one that hugs the top-left corner. A bad classifer will be in a diagonal line from the origin to 1,1.","metadata":{}},{"id":"5336ecb9-305a-4653-bd91-ec32be6e0cb6","cell_type":"markdown","source":"b) When an F1 score is close to 1 that measn that precision and recall are high and the model makes few false positives and false negatives. If the F1 score is close to 0, precision and recall is low and the model performing poorly.","metadata":{}},{"id":"914fb5f4-f116-410c-8f38-c66f9eeaee3e","cell_type":"markdown","source":"## Question 3\n#### Compare the following aspects of linear vs. logistic regression.\n|  | Linear | Logistic |\n|:--------|:--------|:--------|\n| **Chart Shape** | Straight Line  | S shaped |\n| **Dependent Variable Type** | Continuous | Categorical or Binary/Dichotomous |\n| **Purpose** (regression or classification) | Regression | Classification |\n| **Range of output variable** ($y_i$ or $p_i$) | Any real value | probability between 0 and 1 |\n| **Method*** | OLS | MLE |\n| **Example of use** | Prediciting average amount of money people spent on rent based on variables | Prediciting if a patient has a diagnosis |  \n  \n*Meaning ordinary least squares or maximum likelihood estimation","metadata":{}},{"id":"96fbebda-5655-48b1-a2ea-8668e5aa9efe","cell_type":"markdown","source":"## Question 4\n#### Why is it important to train then test our model? How do we do that? (2-3 sentences. Not looking for code, just general explanation).","metadata":{}},{"id":"1321d136-3e9d-4dfc-9de7-df043123b518","cell_type":"markdown","source":"It is important to train and test a model to make sure that it is adaptable and useful for different data not just the exampels provided in creation. This ensures that a model is acutally useful in diverse contexts.","metadata":{}},{"id":"52f265f3-45c5-4efb-8dc5-0cc7c3e8beec","cell_type":"markdown","source":"## Question 5\nThis question runs through a linear regression example. We want to predict median house value based on the other variables.\n#### a) First, load the `housing.csv` data set. Look at the data in some useful way. Why is linear regression appropriate here?","metadata":{}},{"id":"169a566f-615e-48df-9bad-a89c1b2d0426","cell_type":"markdown","source":"#### b) Scale data and split it 75/25 training/testing. Set seed = 123.","metadata":{}},{"id":"439535fe-8224-42d6-9464-ecc6ddc15a44","cell_type":"markdown","source":"#### c) Fit the model.","metadata":{}},{"id":"2a45245e-3ce0-4e07-9b21-0c46e6a3835b","cell_type":"markdown","source":"#### d) Make predictions on test data and show them in an actual vs. predicted plot.","metadata":{}},{"id":"ee52c9ed-31cd-43a6-8e49-91aaee62d650","cell_type":"markdown","source":"#### e) Make a residuals plot.","metadata":{}},{"id":"e4a045c2-cfef-4338-8a5f-11ede6d20dcb","cell_type":"markdown","source":"## Question 6\nThis question runs through a logistic regression example. We want to predict diabetes diagnosis based on the other variables. \n#### a) First, load the `diabetes.csv` data set. Look at the data in some useful way. Why is logistic regression appropriate here?","metadata":{}},{"id":"e3844183-23e8-4a49-99b2-25b3b3191e1f","cell_type":"markdown","source":"#### b) Scale data and split it 75/25 training/testing. Set seed = 123.","metadata":{}},{"id":"9ea27f31-acf0-4913-8bef-5e1e6248503e","cell_type":"markdown","source":"#### c) Fit the model.","metadata":{}},{"id":"c50c2181-60f9-4e62-8579-39dc5763f03a","cell_type":"markdown","source":"#### d) Make predictions on test data. Print a table with the number of true positives, false positives, true negatives, false negatives, and accuracy. ","metadata":{}},{"id":"d7f4d86c-8836-4b34-968d-6e062ddf7562","cell_type":"markdown","source":"#### e) Fit a LASSO-regularized logistic regression model. Again, set seed = 123. Which variables are the most important (which ones don't go to zero)? How does the LASSO model affect the accuracy?","metadata":{}},{"id":"455dd7a9-6502-4261-a8e7-00474fc7b3ef","cell_type":"markdown","source":"#### f) Make a plot of actual vs. predicted values for the LASSO model.","metadata":{}}]}